{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports Marketing Contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import decisiontreeclassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import logisticregression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "#import knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import linear regression classifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# for validating your classification model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# needed for LDA algorithm for missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#t-testing\n",
    "from scipy import stats\n",
    "\n",
    "#regression packages\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#lasso regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "#f_regression (feature selection)\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# recursive feature selection (feature selection)\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modified Final Calibration Set With No Null's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAKEID</th>\n",
       "      <th>Y2defect</th>\n",
       "      <th>Utilrate</th>\n",
       "      <th>Y1price</th>\n",
       "      <th>YEARS</th>\n",
       "      <th>BACKER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>GNDR</th>\n",
       "      <th>OWNHOME</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>PCTMARR</th>\n",
       "      <th>HOMEVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580V74KT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298S54OK</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268D25AO</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312Q12WV</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420R23VB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FAKEID  Y2defect  Utilrate  Y1price  YEARS  BACKER  AGE  INCOME  GNDR  \\\n",
       "0  580V74KT         0       0.6       15      8       1   94       4     0   \n",
       "1  298S54OK         1       0.4       15      3       1   63       3     0   \n",
       "2  268D25AO         1       0.4       15     11       1   67       2     0   \n",
       "3  312Q12WV         1       0.6       15      4       0   62       4     1   \n",
       "4  420R23VB         0       0.2       15      5       0   89       4     1   \n",
       "\n",
       "   OWNHOME  SPORT  PCTMARR  HOMEVAL  \n",
       "0        1      0       77      203  \n",
       "1        0      0       53       68  \n",
       "2        1      0       50       38  \n",
       "3        1      0       60       68  \n",
       "4        1      0       65      194  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrationmod=pd.read_csv(\"datasets/calibration/phase2calibrationfinal.csv\")\n",
    "calibrationmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKEID      0\n",
       "Y2defect    0\n",
       "Utilrate    0\n",
       "Y1price     0\n",
       "YEARS       0\n",
       "BACKER      0\n",
       "AGE         0\n",
       "INCOME      0\n",
       "GNDR        0\n",
       "OWNHOME     0\n",
       "SPORT       0\n",
       "PCTMARR     0\n",
       "HOMEVAL     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrationmod.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the Effect of Utilization Rate on Defect Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y2defect  Utilrate\n",
       "1         0.4         1686\n",
       "          0.2         1561\n",
       "0         0.4         1535\n",
       "          0.6         1316\n",
       "          0.2          994\n",
       "1         0.6          869\n",
       "0         0.8          633\n",
       "1         0.8          406\n",
       "0         1.0          130\n",
       "1         1.0           86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot count of defect among different Utilrates\n",
    "calibrationmod.groupby(['Y2defect','Utilrate']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c1f74bb90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnyiARUR8ogAWEfGJAlhExCcKYBERn/xvOdTcFoetQeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1f74b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#linear regression between x values and Y2defect\n",
    "sns.lmplot(\"Utilrate\", \"Y2defect\", calibrationmod, x_jitter=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation & Heatmap for DF Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y2defect</th>\n",
       "      <th>Utilrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y2defect</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.16472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilrate</th>\n",
       "      <td>-0.16472</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y2defect  Utilrate\n",
       "Y2defect   1.00000  -0.16472\n",
       "Utilrate  -0.16472   1.00000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrationmod[['Y2defect','Utilrate']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As utilization of game passes decreases the likelyhood of someone defecting increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Analysis Using Cross Validation (Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532730560579\n",
      "--------------------------------------------------------\n",
      "[[724 639]\n",
      " [653 749]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53      1363\n",
      "          1       0.54      0.53      0.54      1402\n",
      "\n",
      "avg / total       0.53      0.53      0.53      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.532709011233\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99934895833333337"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf4=clf4.fit(X, y)\n",
    "clf4.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999348958333\n",
      "[[4603    5]\n",
      " [   1 4607]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4608\n",
      "          1       1.00      1.00      1.00      4608\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9216\n",
      "\n",
      "0.999348958333\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(y, clf4.predict(X)) #overall accuracy\n",
    "print metrics.confusion_matrix(y, clf4.predict(X))\n",
    "print metrics.classification_report(y, clf4.predict(X))\n",
    "print metrics.roc_auc_score(y, clf4.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite as good as phase one where utilization rate was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utilrate</td>\n",
       "      <td>0.065308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y1price</td>\n",
       "      <td>0.040236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YEARS</td>\n",
       "      <td>0.136795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BACKER</td>\n",
       "      <td>0.031566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.100749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GNDR</td>\n",
       "      <td>0.034409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SPORT</td>\n",
       "      <td>0.021132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCTMARR</td>\n",
       "      <td>0.256046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOMEVAL</td>\n",
       "      <td>0.313759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0  Utilrate    0.065308\n",
       "1   Y1price    0.040236\n",
       "2     YEARS    0.136795\n",
       "3    BACKER    0.031566\n",
       "4    INCOME    0.100749\n",
       "5      GNDR    0.034409\n",
       "6     SPORT    0.021132\n",
       "7   PCTMARR    0.256046\n",
       "8   HOMEVAL    0.313759"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe to show list of importance in variables\n",
    "pd.DataFrame({'feature':X.columns, 'importance':clf4.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, SPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','SPORT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt2 = DecisionTreeClassifier()\n",
    "dt2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532368896926\n",
      "--------------------------------------------------------\n",
      "[[716 647]\n",
      " [646 756]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53      1363\n",
      "          1       0.54      0.54      0.54      1402\n",
      "\n",
      "avg / total       0.53      0.53      0.53      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.532270742038\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt2.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt2.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt2.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt2.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99924045138888884"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf5=clf5.fit(X, y)\n",
    "clf5.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, SPORT,  OWNHOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','SPORT','OWNHOME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt3 = DecisionTreeClassifier()\n",
    "dt3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542133815552\n",
      "--------------------------------------------------------\n",
      "[[717 646]\n",
      " [620 782]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.53      0.53      1363\n",
      "          1       0.55      0.56      0.55      1402\n",
      "\n",
      "avg / total       0.54      0.54      0.54      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.541910047799\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt3.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt3.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt3.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt3.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99869791666666663"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf6=clf6.fit(X, y)\n",
    "clf6.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, OWNHOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','OWNHOME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt4 = DecisionTreeClassifier()\n",
    "dt4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537793851718\n",
      "--------------------------------------------------------\n",
      "[[717 646]\n",
      " [632 770]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53      1363\n",
      "          1       0.54      0.55      0.55      1402\n",
      "\n",
      "avg / total       0.54      0.54      0.54      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.537630447228\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt4.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt4.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt4.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt4.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99880642361111116"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf7=clf7.fit(X, y)\n",
    "clf7.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, SPORT, GNDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','SPORT','GNDR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt5 = DecisionTreeClassifier()\n",
    "dt5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537070524412\n",
      "--------------------------------------------------------\n",
      "[[718 645]\n",
      " [635 767]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.53      0.53      1363\n",
      "          1       0.54      0.55      0.55      1402\n",
      "\n",
      "avg / total       0.54      0.54      0.54      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.536927384943\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt5.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt5.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt5.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt5.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99761284722222221"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf8=clf8.fit(X, y)\n",
    "clf8.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, OWNHOME, GNDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','OWNHOME','GNDR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt6 = DecisionTreeClassifier()\n",
    "dt6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53164556962\n",
      "--------------------------------------------------------\n",
      "[[718 645]\n",
      " [650 752]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.53      0.53      1363\n",
      "          1       0.54      0.54      0.54      1402\n",
      "\n",
      "avg / total       0.53      0.53      0.53      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.53157788423\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt6.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt6.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt6.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt6.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99761284722222221"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf9 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf9=clf9.fit(X, y)\n",
    "clf9.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Use of the Random Forest 200 trees (Best) on DF calibrationmod Drop Y2defect, FAKEID, AGE, OWNHOME, SPORT, GNDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = calibrationmod['Y2defect']\n",
    "X = calibrationmod.drop(['Y2defect','FAKEID', 'AGE','OWNHOME','SPORT','GNDR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt7 = DecisionTreeClassifier()\n",
    "dt7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541048824593\n",
      "--------------------------------------------------------\n",
      "[[732 631]\n",
      " [638 764]]\n",
      "--------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.54      0.54      1363\n",
      "          1       0.55      0.54      0.55      1402\n",
      "\n",
      "avg / total       0.54      0.54      0.54      2765\n",
      "\n",
      "--------------------------------------------------------\n",
      "0.540993214808\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print metrics.accuracy_score(y_test, dt7.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.confusion_matrix(y_test, dt7.predict(X_test)) \n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.classification_report(y_test, dt7.predict(X_test))\n",
    "print \"--------------------------------------------------------\"\n",
    "print metrics.roc_auc_score(y_test, dt7.predict(X_test))\n",
    "\n",
    "# y-test is the acual y value in the testing dataset\n",
    "# dt.predict(X_test) is the y value generated by your model\n",
    "# If they are same, we can say your model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99761284722222221"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10 = RandomForestClassifier(n_estimators=200)    #building 200 decision trees\n",
    "clf10=clf10.fit(X, y)\n",
    "clf10.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
